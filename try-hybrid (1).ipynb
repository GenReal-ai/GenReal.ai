{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-18T07:38:18.093157Z",
     "iopub.status.busy": "2025-06-18T07:38:18.092965Z",
     "iopub.status.idle": "2025-06-18T07:38:18.942766Z",
     "shell.execute_reply": "2025-06-18T07:38:18.941887Z",
     "shell.execute_reply.started": "2025-06-18T07:38:18.093140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Combining-EfficientNet-and-Vision-Transformers-for-Video-Deepfake-Detection'...\n",
      "remote: Enumerating objects: 162, done.\u001b[K\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 162 (delta 28), reused 14 (delta 14), pack-reused 123 (from 1)\u001b[K\n",
      "Receiving objects: 100% (162/162), 1.10 MiB | 8.27 MiB/s, done.\n",
      "Resolving deltas: 100% (53/53), done.\n",
      "/kaggle/working/Combining-EfficientNet-and-Vision-Transformers-for-Video-Deepfake-Detection\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/davide-coccomini/Combining-EfficientNet-and-Vision-Transformers-for-Video-Deepfake-Detection.git\n",
    "%cd Combining-EfficientNet-and-Vision-Transformers-for-Video-Deepfake-Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:48:12.962473Z",
     "iopub.status.busy": "2025-06-18T07:48:12.962079Z",
     "iopub.status.idle": "2025-06-18T07:48:27.969623Z",
     "shell.execute_reply": "2025-06-18T07:48:27.968897Z",
     "shell.execute_reply.started": "2025-06-18T07:48:12.962447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from efficientnet_pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.17.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->timm) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->timm) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->timm) (2024.2.0)\n",
      "Requirement already satisfied: facenet_pytorch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (1.26.4)\n",
      "Collecting Pillow<10.3.0,>=10.2.0 (from facenet_pytorch)\n",
      "  Using cached pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (2.32.3)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->facenet_pytorch) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->facenet_pytorch) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->facenet_pytorch) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->facenet_pytorch) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->facenet_pytorch) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->facenet_pytorch) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (4.13.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet_pytorch) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.24.0->facenet_pytorch) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.24.0->facenet_pytorch) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.24.0->facenet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0,>=1.24.0->facenet_pytorch) (2024.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0,>=1.24.0->facenet_pytorch) (2024.2.0)\n",
      "Using cached pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Installing collected packages: Pillow\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.5.0\n",
      "    Uninstalling Pillow-9.5.0:\n",
      "      Successfully uninstalled Pillow-9.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-10.2.0\n",
      "Collecting pillow==9.5.0\n",
      "  Using cached Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Using cached Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Installing collected packages: pillow\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.2.0\n",
      "    Uninstalling pillow-10.2.0:\n",
      "      Successfully uninstalled pillow-10.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 9.5.0 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.5.0 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pillow-9.5.0\n",
      "Requirement already satisfied: insightface==0.7.3 in /usr/local/lib/python3.11/dist-packages (0.7.3)\n",
      "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.22.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (1.26.4)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (3.7.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (9.5.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (1.2.2)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (0.25.2)\n",
      "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (1.13)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (3.0.12)\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (2.0.5)\n",
      "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from insightface==0.7.3) (3.16.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->insightface==0.7.3) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->insightface==0.7.3) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->insightface==0.7.3) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->insightface==0.7.3) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->insightface==0.7.3) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->insightface==0.7.3) (2.4.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface==0.7.3) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface==0.7.3) (2.11.4)\n",
      "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface==0.7.3) (0.0.23)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface==0.7.3) (4.11.0.86)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->insightface==0.7.3) (3.12.3)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->insightface==0.7.3) (6.2.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.7.3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.7.3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.7.3) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.7.3) (1.4.8)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.7.3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.7.3) (2.9.0.post0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->insightface==0.7.3) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.7.3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.7.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.7.3) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.7.3) (2025.4.26)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.7.3) (3.4.2)\n",
      "Collecting Pillow (from insightface==0.7.3)\n",
      "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.7.3) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.7.3) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.7.3) (0.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface==0.7.3) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface==0.7.3) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface==0.7.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface==0.7.3) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface==0.7.3) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface==0.7.3) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface==0.7.3) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->insightface==0.7.3) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->insightface==0.7.3) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->insightface==0.7.3) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->insightface==0.7.3) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->insightface==0.7.3) (2024.2.0)\n",
      "Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.5.0\n",
      "    Uninstalling Pillow-9.5.0:\n",
      "      Successfully uninstalled Pillow-9.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.2.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-11.2.1\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install necessary libraries\n",
    "!pip install efficientnet_pytorch einops timm\n",
    "!pip install facenet_pytorch\n",
    "# !pip install insightface onnxruntime\n",
    "!pip install pillow==9.5.0\n",
    "!pip install insightface==0.7.3 onnxruntime\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:46:21.180741Z",
     "iopub.status.busy": "2025-06-18T07:46:21.180452Z",
     "iopub.status.idle": "2025-06-18T07:46:25.060886Z",
     "shell.execute_reply": "2025-06-18T07:46:25.059670Z",
     "shell.execute_reply.started": "2025-06-18T07:46:21.180719Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow<10\n",
      "  Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.2.0\n",
      "    Uninstalling pillow-10.2.0:\n",
      "      Successfully uninstalled pillow-10.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 9.5.0 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.5.0 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pillow-9.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"pillow<10\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:48:32.027643Z",
     "iopub.status.busy": "2025-06-18T07:48:32.026975Z",
     "iopub.status.idle": "2025-06-18T07:48:37.611193Z",
     "shell.execute_reply": "2025-06-18T07:48:37.610609Z",
     "shell.execute_reply.started": "2025-06-18T07:48:32.027613Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Imports\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import timm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:48:42.806614Z",
     "iopub.status.busy": "2025-06-18T07:48:42.805916Z",
     "iopub.status.idle": "2025-06-18T07:48:42.810859Z",
     "shell.execute_reply": "2025-06-18T07:48:42.810110Z",
     "shell.execute_reply.started": "2025-06-18T07:48:42.806590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Config \n",
    "class DotDict(dict):\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "config = DotDict({\n",
    "    'model': DotDict({\n",
    "        'image_size': 224,\n",
    "        'patch_size': 16,\n",
    "        'in_channels': 3,\n",
    "        'emb_dim': 512,\n",
    "        'num_classes': 2,\n",
    "        'dropout': 0.1\n",
    "    }),\n",
    "    'training': DotDict({\n",
    "        'batch_size': 32,\n",
    "        'lr': 0.001,\n",
    "        'weight_decay': 0.0001,\n",
    "        'step_size': 5,\n",
    "        'gamma': 0.5\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:54:48.935694Z",
     "iopub.status.busy": "2025-06-18T07:54:48.934814Z",
     "iopub.status.idle": "2025-06-18T07:54:49.262132Z",
     "shell.execute_reply": "2025-06-18T07:54:49.261309Z",
     "shell.execute_reply.started": "2025-06-18T07:54:48.935666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SOURCE_DIR = \"/kaggle/input/archive-try/uadfv\"\n",
    "DEST_DIR = \"/kaggle/working/split_dataset\"\n",
    "CLASSES = [\"real\", \"fake\"]\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Create split directories\n",
    "for split in SPLITS:\n",
    "    for cls in CLASSES:\n",
    "        os.makedirs(os.path.join(DEST_DIR, split, cls), exist_ok=True)\n",
    "\n",
    "def split_and_copy(cls):\n",
    "    files = sorted(os.listdir(os.path.join(SOURCE_DIR, cls)))\n",
    "    train_val, test = train_test_split(files, test_size=0.15, random_state=42)\n",
    "    train, val = train_test_split(train_val, test_size=0.176, random_state=42)  # ~15% val\n",
    "\n",
    "    for split, split_files in zip(SPLITS, [train, val, test]):\n",
    "        for f in split_files:\n",
    "            shutil.copy(os.path.join(SOURCE_DIR, cls, f), os.path.join(DEST_DIR, split, cls, f))\n",
    "\n",
    "for cls in CLASSES:\n",
    "    split_and_copy(cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:56:02.915048Z",
     "iopub.status.busy": "2025-06-18T07:56:02.914301Z",
     "iopub.status.idle": "2025-06-18T08:26:54.411975Z",
     "shell.execute_reply": "2025-06-18T08:26:54.411194Z",
     "shell.execute_reply.started": "2025-06-18T07:56:02.915024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train/real: 100%|██████████| 33/33 [09:39<00:00, 17.57s/it]\n",
      "train/fake: 100%|██████████| 33/33 [09:15<00:00, 16.84s/it]\n",
      "val/real: 100%|██████████| 8/8 [02:10<00:00, 16.33s/it]\n",
      "val/fake: 100%|██████████| 8/8 [02:11<00:00, 16.44s/it]\n",
      "test/real: 100%|██████████| 8/8 [03:21<00:00, 25.19s/it]\n",
      "test/fake: 100%|██████████| 8/8 [03:22<00:00, 25.25s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import insightface\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize InsightFace model\n",
    "model = insightface.app.FaceAnalysis(name='buffalo_l')\n",
    "model.prepare(ctx_id=0 )  # Use 0 for GPU, -1 for CPU\n",
    "\n",
    "# Define base paths\n",
    "SPLITS = ['train', 'val', 'test']\n",
    "INPUT_BASE = '/kaggle/working/split_dataset'\n",
    "OUTPUT_BASE = '/kaggle/working/cropped_faces'\n",
    "\n",
    "# Loop through splits and classes\n",
    "for split in SPLITS:\n",
    "    for label in ['real', 'fake']:\n",
    "        input_folder = os.path.join(INPUT_BASE, split, label)\n",
    "        output_folder = os.path.join(OUTPUT_BASE, split, label)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        video_files = [f for f in os.listdir(input_folder) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "\n",
    "        for video_name in tqdm(video_files, desc=f\"{split}/{label}\"):\n",
    "            video_path = os.path.join(input_folder, video_name)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            \n",
    "            frame_idx = 0\n",
    "            saved_faces = 0\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                # Sample every 10th frame\n",
    "                if frame_idx % 10 == 0:\n",
    "                    # InsightFace expects BGR directly\n",
    "                    faces = model.get(frame)\n",
    "                    \n",
    "                    for i, face in enumerate(faces):\n",
    "                        x1, y1, x2, y2 = face.bbox.astype(int)\n",
    "\n",
    "                        # Optional: add margin\n",
    "                        margin_ratio = 0.2\n",
    "                        w, h = x2 - x1, y2 - y1\n",
    "                        x1 = max(0, int(x1 - w * margin_ratio))\n",
    "                        y1 = max(0, int(y1 - h * margin_ratio))\n",
    "                        x2 = min(frame.shape[1], int(x2 + w * margin_ratio))\n",
    "                        y2 = min(frame.shape[0], int(y2 + h * margin_ratio))\n",
    "\n",
    "                        face_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "                        # Save face crop\n",
    "                        face_path = os.path.join(output_folder, f\"{video_name}_{frame_idx}_{i}.jpg\")\n",
    "                        cv2.imwrite(face_path, face_crop)\n",
    "                        saved_faces += 1\n",
    "\n",
    "                frame_idx += 1\n",
    "\n",
    "            cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T08:27:10.212007Z",
     "iopub.status.busy": "2025-06-18T08:27:10.211215Z",
     "iopub.status.idle": "2025-06-18T08:27:10.217736Z",
     "shell.execute_reply": "2025-06-18T08:27:10.216995Z",
     "shell.execute_reply.started": "2025-06-18T08:27:10.211982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for label_folder in os.listdir(image_folder):\n",
    "            label_path = os.path.join(image_folder, label_folder)\n",
    "            label = 0 if label_folder == 'real' else 1\n",
    "            for img_file in os.listdir(label_path):\n",
    "                self.images.append(os.path.join(label_path, img_file))\n",
    "                self.labels.append(label)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T08:27:14.185846Z",
     "iopub.status.busy": "2025-06-18T08:27:14.185364Z",
     "iopub.status.idle": "2025-06-18T08:27:14.194578Z",
     "shell.execute_reply": "2025-06-18T08:27:14.193932Z",
     "shell.execute_reply.started": "2025-06-18T08:27:14.185823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Model\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, in_channels, emb_dim):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, \"Image size must be divisible by patch size\"\n",
    "        self.num_patches = (image_size // patch_size) ** 2\n",
    "        self.proj = nn.Conv2d(in_channels, emb_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches, emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # [B, emb_dim, H/patch, W/patch]\n",
    "        x = x.flatten(2).transpose(1, 2)  # [B, num_patches, emb_dim]\n",
    "        x = x + self.pos_embed  # Add positional encoding\n",
    "        return x\n",
    "    \n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads=8, ff_hidden_mult=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.msa = nn.MultiheadAttention(emb_dim, num_heads, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, ff_hidden_mult * emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(ff_hidden_mult * emb_dim, emb_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_res = x + self.msa(self.ln1(x), self.ln1(x), self.ln1(x))[0]\n",
    "        x_res = x_res + self.mlp(self.ln2(x_res))\n",
    "        return x_res\n",
    "\n",
    "class EfficientViT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "        self.patch_embed = PatchEmbedding(\n",
    "            image_size=config.image_size,\n",
    "            patch_size=config.patch_size,\n",
    "            in_channels=config.in_channels,\n",
    "            emb_dim=config.emb_dim\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(emb_dim=config.emb_dim, num_heads=8, dropout=config.dropout)\n",
    "        self.fc = nn.Linear(config.emb_dim + 1280, config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_out = self.efficientnet.extract_features(x)\n",
    "        eff_out = nn.functional.adaptive_avg_pool2d(eff_out, 1).squeeze(-1).squeeze(-1)\n",
    "        vit_input = self.patch_embed(x)\n",
    "        vit_out = self.transformer(vit_input).mean(dim=1)\n",
    "        combined = torch.cat((eff_out, vit_out), dim=1)\n",
    "        return self.fc(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T08:27:47.189086Z",
     "iopub.status.busy": "2025-06-18T08:27:47.188323Z",
     "iopub.status.idle": "2025-06-18T08:27:47.199141Z",
     "shell.execute_reply": "2025-06-18T08:27:47.198400Z",
     "shell.execute_reply.started": "2025-06-18T08:27:47.189063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 6: Load Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Replace with your actual dataset path on Kaggle\n",
    "train_dataset = CustomDataset(\"/kaggle/working/cropped_faces/train\", transform=transform)\n",
    "test_dataset = CustomDataset(\"/kaggle/working/cropped_faces/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.training.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.training.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T08:27:51.489788Z",
     "iopub.status.busy": "2025-06-18T08:27:51.489275Z",
     "iopub.status.idle": "2025-06-18T08:27:51.493313Z",
     "shell.execute_reply": "2025-06-18T08:27:51.492555Z",
     "shell.execute_reply.started": "2025-06-18T08:27:51.489765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create checkpoint folder\n",
    "checkpoint_dir = \"/kaggle/working/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T08:49:42.417618Z",
     "iopub.status.busy": "2025-06-18T08:49:42.416829Z",
     "iopub.status.idle": "2025-06-18T08:49:42.424777Z",
     "shell.execute_reply": "2025-06-18T08:49:42.423997Z",
     "shell.execute_reply.started": "2025-06-18T08:49:42.417596Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/Combining-EfficientNet-and-Vision-Transformers-for-Video-Deepfake-Detection/efficient-vit/efficient_vit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/Combining-EfficientNet-and-Vision-Transformers-for-Video-Deepfake-Detection/efficient-vit/efficient_vit.py\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
    "            ]) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class EfficientViT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        image_size = config['model']['image-size']\n",
    "        patch_size = config['model']['patch-size']\n",
    "        num_classes = config['model']['num-classes']\n",
    "        dim = config['model']['dim']\n",
    "        depth = config['model']['depth']\n",
    "        heads = config['model']['heads']\n",
    "        mlp_dim = config['model']['mlp-dim']\n",
    "        emb_dim = config['model']['emb-dim']\n",
    "        dim_head = config['model']['dim-head']\n",
    "        dropout = config['model']['dropout']\n",
    "        emb_dropout = config['model']['emb-dropout']\n",
    "\n",
    "        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n",
    "\n",
    "        self.efficient_net = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        for param in self.efficient_net.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        channels = 1280  # EfficientNet-b0 output channels\n",
    "        num_patches = (7 // patch_size) ** 2\n",
    "        patch_dim = channels * patch_size ** 2\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout_layer = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        p = self.patch_size\n",
    "        x = self.efficient_net.extract_features(img)  # (B, 1280, 7, 7)\n",
    "        x = rearrange(x, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=p, p2=p)\n",
    "        x = self.patch_to_embedding(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(img.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :x.shape[1], :]\n",
    "        x = self.dropout_layer(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, 0]\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T08:56:29.288250Z",
     "iopub.status.busy": "2025-06-18T08:56:29.287523Z",
     "iopub.status.idle": "2025-06-18T09:07:08.103275Z",
     "shell.execute_reply": "2025-06-18T09:07:08.102264Z",
     "shell.execute_reply.started": "2025-06-18T08:56:29.288219Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 70/70 [00:19<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.3066\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_1.pth\n",
      "Validation Accuracy: 0.5136, F1 Score: 0.6740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 70/70 [00:19<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 0.0732\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_2.pth\n",
      "Validation Accuracy: 0.7223, F1 Score: 0.7836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 70/70 [00:19<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Loss: 0.0348\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_3.pth\n",
      "Validation Accuracy: 0.6334, F1 Score: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 70/70 [00:19<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Loss: 0.0247\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_4.pth\n",
      "Validation Accuracy: 0.8004, F1 Score: 0.8343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Loss: 0.0152\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_5.pth\n",
      "Validation Accuracy: 0.8784, F1 Score: 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 70/70 [00:19<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Loss: 0.0126\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_6.pth\n",
      "Validation Accuracy: 0.9093, F1 Score: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Loss: 0.0095\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_7.pth\n",
      "Validation Accuracy: 0.9038, F1 Score: 0.9106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Loss: 0.0089\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_8.pth\n",
      "Validation Accuracy: 0.9093, F1 Score: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Loss: 0.0079\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_9.pth\n",
      "Validation Accuracy: 0.9038, F1 Score: 0.9078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 0.0105\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_10.pth\n",
      "Validation Accuracy: 0.8984, F1 Score: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Loss: 0.0263\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_11.pth\n",
      "Validation Accuracy: 0.9038, F1 Score: 0.9115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 70/70 [00:19<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Loss: 0.0161\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_12.pth\n",
      "Validation Accuracy: 0.9074, F1 Score: 0.9154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 70/70 [00:19<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Loss: 0.0198\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_13.pth\n",
      "Validation Accuracy: 0.8875, F1 Score: 0.8860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 70/70 [00:19<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Loss: 0.0296\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_14.pth\n",
      "Validation Accuracy: 0.8875, F1 Score: 0.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Loss: 0.0094\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_15.pth\n",
      "Validation Accuracy: 0.9020, F1 Score: 0.9094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Loss: 0.0162\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_16.pth\n",
      "Validation Accuracy: 0.9074, F1 Score: 0.9154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Loss: 0.0240\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_17.pth\n",
      "Validation Accuracy: 0.9020, F1 Score: 0.9094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 70/70 [00:19<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Loss: 0.0312\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_18.pth\n",
      "Validation Accuracy: 0.9056, F1 Score: 0.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Loss: 0.0181\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_19.pth\n",
      "Validation Accuracy: 0.9056, F1 Score: 0.9136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 70/70 [00:19<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Loss: 0.0109\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_20.pth\n",
      "Validation Accuracy: 0.9038, F1 Score: 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Loss: 0.0095\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_21.pth\n",
      "Validation Accuracy: 0.9093, F1 Score: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 70/70 [00:19<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Loss: 0.0123\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_22.pth\n",
      "Validation Accuracy: 0.9002, F1 Score: 0.9069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Loss: 0.0131\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_23.pth\n",
      "Validation Accuracy: 0.8947, F1 Score: 0.9003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Loss: 0.0077\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_24.pth\n",
      "Validation Accuracy: 0.8984, F1 Score: 0.9057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Loss: 0.0089\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_25.pth\n",
      "Validation Accuracy: 0.8947, F1 Score: 0.9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 70/70 [00:19<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Loss: 0.0077\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_26.pth\n",
      "Validation Accuracy: 0.8947, F1 Score: 0.9027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Loss: 0.0066\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_27.pth\n",
      "Validation Accuracy: 0.9074, F1 Score: 0.9154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 70/70 [00:19<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Loss: 0.0051\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_28.pth\n",
      "Validation Accuracy: 0.9074, F1 Score: 0.9154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Loss: 0.0016\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_29.pth\n",
      "Validation Accuracy: 0.9074, F1 Score: 0.9154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 70/70 [00:19<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Loss: 0.0070\n",
      "Saved checkpoint: /kaggle/working/checkpoints/model_epoch_30.pth\n",
      "Validation Accuracy: 0.9093, F1 Score: 0.9172\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add path to efficient_vit\n",
    "sys.path.append('/kaggle/working/Combining-EfficientNet-and-Vision-Transformers-for-Video-Deepfake-Detection/efficient-vit')\n",
    "\n",
    "# Import EfficientViT model\n",
    "from efficient_vit import EfficientViT\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 30\n",
    "num_classes = 2  # real, fake\n",
    "\n",
    "# Image size (make sure this matches what efficient_vit expects)\n",
    "image_size = 224\n",
    "\n",
    "# Transforms (NO albumentations)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load dataset using ImageFolder (folder structure must be: class_name/image.jpg)\n",
    "train_dataset = datasets.ImageFolder(root='/kaggle/working/cropped_faces/train', transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(root='/kaggle/working/cropped_faces/val', transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Create config dictionary as expected by EfficientViT\n",
    "config = {\n",
    "    'model': {\n",
    "        'image-size': image_size,\n",
    "        'patch-size': 1,   # In your model it's 1 because EfficientNet output is 7x7\n",
    "        'num-classes': num_classes,\n",
    "        'dim': 512,\n",
    "        'depth': 6,\n",
    "        'heads': 8,\n",
    "        'mlp-dim': 1024,\n",
    "        'emb-dim': 512,\n",
    "        'dim-head': 64,\n",
    "        'dropout': 0.1,\n",
    "        'emb-dropout': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = EfficientViT(config).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Directory for saving checkpoints\n",
    "checkpoint_dir = \"/kaggle/working/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch+1}.pth\")\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7681365,
     "sourceId": 12194575,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
